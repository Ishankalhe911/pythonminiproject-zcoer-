## ğŸ“… Day 16 â€” Data Normalization & Scaling (Foundations for ML)

### ğŸ¯ Objective

Strengthen Python fundamentals while building **ML-ready data discipline**:

* avoid data mutation
* handle edge cases explicitly
* translate math definitions into reliable code

---

## âœ… Concepts Covered

* Manual implementation of:

  * Minimum & Maximum
  * Mean Normalization
  * Minâ€“Max Scaling
* Error handling for invalid data
* Design decisions for degenerate datasets
* Understanding why normalization matters in ML

---

## ğŸ§© Implemented Functions

### 1. Manual Min & Max (No Built-ins)

* One-pass traversal
* Handles empty list via `ValueError`
* Single-element lists supported naturally

**Key learning:**
Min/max does **not** require sorting â†’ `O(n)` vs `O(n log n)`

---

### 2. Mean Normalization

**Formula:**

```
x_norm = x âˆ’ Î¼
```

**Behavior:**

* Returns a new list
* Does NOT modify input data
* Preserves shape (N â†’ N)

**Example:**

```
[10, 20, 30] â†’ [-10, 0, 10]
```

**Insight:**
Normalization is a **data transformation**, not aggregation.

---

### 3. Minâ€“Max Scaling

**Formula:**

```
x' = (x âˆ’ min) / (max âˆ’ min)
```

**Edge-case handling:**

* Empty list â†’ error
* All values equal â†’ return all zeros
* Single value â†’ `[0]`

**Reasoning:**

* Constant features have no variance
* Returning zeros keeps pipelines stable
* Errors are for invalid data, not uninformative data

---

## ğŸ§  ML Insight Gained

* Models donâ€™t understand units, only magnitudes
* Unscaled features distort optimization
* Normalization reshapes the learning space
* Data hygiene comes **before** models

---

## âš ï¸ Common Pitfalls Identified & Fixed

* Returning generators instead of lists
* Placing `return` inside loops
* Silent division-by-zero errors
* Mutating input data unintentionally

---

## ğŸ§± Engineering Takeaways

* Correctness > shortcuts
* Explicit logic > clever syntax
* Robust behavior > â€œcode that runsâ€

---

## ğŸ“Œ Status

âœ” Day 16 completed
âœ” Code committed
âœ” Ready to move to variance & standard deviation


